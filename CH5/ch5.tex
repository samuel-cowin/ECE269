\documentclass[12pt]{article}
\usepackage{amsmath, bm, amssymb}
\usepackage{tikz, pgfplots}
\pgfplotsset{compat=1.17}
\usepackage[a4paper,bindingoffset=0.2in,left=1in,right=1in,top=1in,bottom=1in,footskip=.25in]{geometry}

\begin{document}
\setlength{\abovedisplayskip}{0pt}
\setlength{\belowdisplayskip}{0pt}
\setlength{\abovedisplayshortskip}{0pt}
\setlength{\belowdisplayshortskip}{0pt}

\title{Notes for ECE269 - Linear Algebra \\
\large Chapter 4}
\author{Sam Cowin}
\maketitle

\section{Linear Equations in Linear Algebra}
\section{Matrix Algebra}
\section{Determinants}
\section{Vector Spaces}
\section{Eigenvalues and Eigenvectors}
Eigenvalues and Eigenvectors appear in many systems, but concerning engineering, the appear in differential equations and continuous dynamical systems. These systems are another way to refer
to difference equations. The dynamical system describes the lienar transformations from one state to the next state, and the Eigenvalues and Eigenvectors help visualize and disect these 
transformations. 
\subsection{Eigenvectors and Eigenvalues}
An eigenvector of an \textit{n x n} matrix A is a nonzero vector \textbf{x} such that $A\mathbf{x}=\lambda\mathbf{x}$ for some scalar $\lambda$. A scalar $\lambda$ is called an eigenvalue of 
A if there is a nontrivial solution \textbf{x} of A\textbf{x}=$\lambda$\textbf{x}; such an \textbf{x} is called an eigenvector corresponding to $\lambda$. $\lambda$ is a eigenvalue of 
the \textit{n x n} matrix A if and only if there is a nontrivial solution to the equation $(A-\lambda I)\mathbf{x=0}$. The eigenspace is a subspace of the null space. Finding a basis for 
the eigenspace is the equivalent of solving the homogeneous equation just described and finding the vector equation corresponding to that solution. while this method works for finding the 
eigenvectors, the reduced echelon form does not showcase the eigenvalues. For there to be a nontrivial solution, to restate there needs to be linear dependence among the columns or free 
variables. One such case where eigenvalues can be found precisely is when you have a triangular matrix and the eigenvalues are the entries of the main diagonol. This is the 
case for the lower triangular matrices as well and repeats are treated as one eigenvalue. Zero can only be an eigenvalue of a matrix if that matrix is not invertible. If there is a set 
of eigenvectors that each correspond to a distinct eigenvalue, then these vectors are linearly independent. One simple way to solve the difference equations is to replace the 
previous state multiplied with the matrix A by the matrix A multiplied with the initial state eigenvector multiplied with eigenvalue of this state to the previous states power. The 
transformation matrix raised to any power multiplied with \textbf{x} is equivalent to the eigenvalue raised to the same power multiplied with \textbf{x}. Multiples of eigenvalues are 
eigenvalues for the same scalar multiple of the matrix that the original eigenvalue was an eigenvalue for. 

\end{document}